{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5836ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ML models applied to WPBC\n",
    "## Highest accuracy got is 87.87 got by LGBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174878e",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ba8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #used in code line 6\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt #used in PCA line 81 \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d87751",
   "metadata": {},
   "source": [
    "## Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1ca764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/lenovo/Downloads/archive/wpbc.data.csv\")\n",
    "#https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(Prognostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e87b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198 entries, 0 to 197\n",
      "Data columns (total 35 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       198 non-null    int64  \n",
      " 1   Recurrence               198 non-null    object \n",
      " 2   Time                     198 non-null    int64  \n",
      " 3   radius_mean              198 non-null    float64\n",
      " 4   texture_mean             198 non-null    float64\n",
      " 5   perimeter_mean           198 non-null    float64\n",
      " 6   area_mean                198 non-null    float64\n",
      " 7   smoothness_mean          198 non-null    float64\n",
      " 8   compactness_mean         198 non-null    float64\n",
      " 9   concavity_mean           198 non-null    float64\n",
      " 10  concave points_mean      198 non-null    float64\n",
      " 11  symmetry_mean            198 non-null    float64\n",
      " 12  fractal_dimension_mean   198 non-null    float64\n",
      " 13  radius_se                198 non-null    float64\n",
      " 14  texture_se               198 non-null    float64\n",
      " 15  perimeter_se             198 non-null    float64\n",
      " 16  area_se                  198 non-null    float64\n",
      " 17  smoothness_se            198 non-null    float64\n",
      " 18  compactness_se           198 non-null    float64\n",
      " 19  concavity_se             198 non-null    float64\n",
      " 20  concave points_se        198 non-null    float64\n",
      " 21  symmetry_se              198 non-null    float64\n",
      " 22  fractal_dimension_se     198 non-null    float64\n",
      " 23  radius_worst             198 non-null    float64\n",
      " 24  texture_worst            198 non-null    float64\n",
      " 25  perimeter_worst          198 non-null    float64\n",
      " 26  area_worst               198 non-null    float64\n",
      " 27  smoothness_worst         198 non-null    float64\n",
      " 28  compactness_worst        198 non-null    float64\n",
      " 29  concavity_worst          198 non-null    float64\n",
      " 30  concave points_worst     198 non-null    float64\n",
      " 31  symmetry_worst           198 non-null    float64\n",
      " 32  fractal_dimension_worst  198 non-null    float64\n",
      " 33  Tumor Size               198 non-null    float64\n",
      " 34  Lymph node status        198 non-null    object \n",
      "dtypes: float64(31), int64(2), object(2)\n",
      "memory usage: 54.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fb094",
   "metadata": {},
   "source": [
    "## Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be7e06f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5.1', '2', '0', '?', '10', '1', '20', '6', '13', '4', '17', '15',\n",
       "       '11', '9', '8', '7', '3', '14', '27', '5', '24', '18', '16', '21'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Lymph node status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef97c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lymph node status']=df['Lymph node status'].apply(lambda x: np.nan if x == '?' else x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcdb6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lymph node status']=df['Lymph node status'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3ed810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198 entries, 0 to 197\n",
      "Data columns (total 35 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       198 non-null    int64  \n",
      " 1   Recurrence               198 non-null    object \n",
      " 2   Time                     198 non-null    int64  \n",
      " 3   radius_mean              198 non-null    float64\n",
      " 4   texture_mean             198 non-null    float64\n",
      " 5   perimeter_mean           198 non-null    float64\n",
      " 6   area_mean                198 non-null    float64\n",
      " 7   smoothness_mean          198 non-null    float64\n",
      " 8   compactness_mean         198 non-null    float64\n",
      " 9   concavity_mean           198 non-null    float64\n",
      " 10  concave points_mean      198 non-null    float64\n",
      " 11  symmetry_mean            198 non-null    float64\n",
      " 12  fractal_dimension_mean   198 non-null    float64\n",
      " 13  radius_se                198 non-null    float64\n",
      " 14  texture_se               198 non-null    float64\n",
      " 15  perimeter_se             198 non-null    float64\n",
      " 16  area_se                  198 non-null    float64\n",
      " 17  smoothness_se            198 non-null    float64\n",
      " 18  compactness_se           198 non-null    float64\n",
      " 19  concavity_se             198 non-null    float64\n",
      " 20  concave points_se        198 non-null    float64\n",
      " 21  symmetry_se              198 non-null    float64\n",
      " 22  fractal_dimension_se     198 non-null    float64\n",
      " 23  radius_worst             198 non-null    float64\n",
      " 24  texture_worst            198 non-null    float64\n",
      " 25  perimeter_worst          198 non-null    float64\n",
      " 26  area_worst               198 non-null    float64\n",
      " 27  smoothness_worst         198 non-null    float64\n",
      " 28  compactness_worst        198 non-null    float64\n",
      " 29  concavity_worst          198 non-null    float64\n",
      " 30  concave points_worst     198 non-null    float64\n",
      " 31  symmetry_worst           198 non-null    float64\n",
      " 32  fractal_dimension_worst  198 non-null    float64\n",
      " 33  Tumor Size               198 non-null    float64\n",
      " 34  Lymph node status        194 non-null    float64\n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 54.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270edda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lymph node status']=df['Lymph node status'].fillna(df['Lymph node status'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bea3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,2:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f02d9f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Lymph node status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>0.07055</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>...</td>\n",
       "      <td>139.70</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>0.11950</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>...</td>\n",
       "      <td>159.10</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.11880</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.20320</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>10</td>\n",
       "      <td>22.52</td>\n",
       "      <td>21.92</td>\n",
       "      <td>146.90</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>0.07592</td>\n",
       "      <td>0.09162</td>\n",
       "      <td>0.06862</td>\n",
       "      <td>0.06367</td>\n",
       "      <td>0.1728</td>\n",
       "      <td>...</td>\n",
       "      <td>162.10</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>0.08191</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.09378</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.05788</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>8</td>\n",
       "      <td>15.44</td>\n",
       "      <td>31.18</td>\n",
       "      <td>101.00</td>\n",
       "      <td>740.4</td>\n",
       "      <td>0.09399</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.13750</td>\n",
       "      <td>0.06500</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>...</td>\n",
       "      <td>112.60</td>\n",
       "      <td>929.0</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.12860</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.08024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>12</td>\n",
       "      <td>17.17</td>\n",
       "      <td>29.19</td>\n",
       "      <td>110.00</td>\n",
       "      <td>915.3</td>\n",
       "      <td>0.08952</td>\n",
       "      <td>0.06655</td>\n",
       "      <td>0.06583</td>\n",
       "      <td>0.05068</td>\n",
       "      <td>0.1793</td>\n",
       "      <td>...</td>\n",
       "      <td>132.50</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>0.12610</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.09520</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.06033</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3</td>\n",
       "      <td>21.42</td>\n",
       "      <td>22.84</td>\n",
       "      <td>145.00</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.19390</td>\n",
       "      <td>0.23800</td>\n",
       "      <td>0.13180</td>\n",
       "      <td>0.1884</td>\n",
       "      <td>...</td>\n",
       "      <td>198.30</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>0.14980</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.22150</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.08981</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.211856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6</td>\n",
       "      <td>16.70</td>\n",
       "      <td>28.13</td>\n",
       "      <td>110.30</td>\n",
       "      <td>885.4</td>\n",
       "      <td>0.08896</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.04989</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>...</td>\n",
       "      <td>128.80</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.13170</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.08036</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      31        18.02         27.60          117.50     1013.0   \n",
       "1      61        17.99         10.38          122.80     1001.0   \n",
       "2     116        21.37         17.44          137.50     1373.0   \n",
       "3     123        11.42         20.38           77.58      386.1   \n",
       "4      27        20.29         14.34          135.10     1297.0   \n",
       "..    ...          ...           ...             ...        ...   \n",
       "193    10        22.52         21.92          146.90     1597.0   \n",
       "194     8        15.44         31.18          101.00      740.4   \n",
       "195    12        17.17         29.19          110.00      915.3   \n",
       "196     3        21.42         22.84          145.00     1440.0   \n",
       "197     6        16.70         28.13          110.30      885.4   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.09489           0.10360         0.10860              0.07055   \n",
       "1            0.11840           0.27760         0.30010              0.14710   \n",
       "2            0.08836           0.11890         0.12550              0.08180   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "193          0.07592           0.09162         0.06862              0.06367   \n",
       "194          0.09399           0.10620         0.13750              0.06500   \n",
       "195          0.08952           0.06655         0.06583              0.05068   \n",
       "196          0.10700           0.19390         0.23800              0.13180   \n",
       "197          0.08896           0.11310         0.10120              0.04989   \n",
       "\n",
       "     symmetry_mean  ...  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0           0.1865  ...           139.70      1436.0           0.11950   \n",
       "1           0.2419  ...           184.60      2019.0           0.16220   \n",
       "2           0.2333  ...           159.10      1949.0           0.11880   \n",
       "3           0.2597  ...            98.87       567.7           0.20980   \n",
       "4           0.1809  ...           152.20      1575.0           0.13740   \n",
       "..             ...  ...              ...         ...               ...   \n",
       "193         0.1728  ...           162.10      1902.0           0.08191   \n",
       "194         0.1735  ...           112.60       929.0           0.12720   \n",
       "195         0.1793  ...           132.50      1295.0           0.12610   \n",
       "196         0.1884  ...           198.30      2375.0           0.14980   \n",
       "197         0.1890  ...           128.80      1213.0           0.13300   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0               0.1926           0.3140               0.11700          0.2677   \n",
       "1               0.6656           0.7119               0.26540          0.4601   \n",
       "2               0.3449           0.3414               0.20320          0.4334   \n",
       "3               0.8663           0.6869               0.25750          0.6638   \n",
       "4               0.2050           0.4000               0.16250          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "193             0.1319           0.1056               0.09378          0.2061   \n",
       "194             0.2362           0.2975               0.12860          0.2914   \n",
       "195             0.1572           0.2141               0.09520          0.3362   \n",
       "196             0.4379           0.5411               0.22150          0.2832   \n",
       "197             0.2808           0.3455               0.13170          0.3035   \n",
       "\n",
       "     fractal_dimension_worst  Tumor Size  Lymph node status  \n",
       "0                    0.08113         5.0           5.100000  \n",
       "1                    0.11890         3.0           2.000000  \n",
       "2                    0.09067         2.5           0.000000  \n",
       "3                    0.17300         2.0           0.000000  \n",
       "4                    0.07678         3.5           0.000000  \n",
       "..                       ...         ...                ...  \n",
       "193                  0.05788         6.0           2.000000  \n",
       "194                  0.08024         1.5           0.000000  \n",
       "195                  0.06033         3.7           0.000000  \n",
       "196                  0.08981         3.0           3.211856  \n",
       "197                  0.08036         3.5           0.000000  \n",
       "\n",
       "[198 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84efb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Recurrence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d6f6e",
   "metadata": {},
   "source": [
    "## Removing correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37efdf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.995933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.995933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>area_mean</td>\n",
       "      <td>0.992855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.992855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.990699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1        feature2  Correlation\n",
       "0  perimeter_mean     radius_mean     0.995933\n",
       "1     radius_mean  perimeter_mean     0.995933\n",
       "2     radius_mean       area_mean     0.992855\n",
       "3       area_mean     radius_mean     0.992855\n",
       "4       area_mean  perimeter_mean     0.990699"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Dataframe with Correlation between Features\n",
    "corr_matrix = X.corr()\n",
    "# Take absolute values of correlated coefficients\n",
    "corr_matrix = corr_matrix.abs().unstack()\n",
    "corr_matrix = corr_matrix.sort_values(ascending=False)\n",
    "# Take only features with correlation above threshold of 0.8\n",
    "corr_matrix = corr_matrix[corr_matrix >= 0.8]\n",
    "corr_matrix = corr_matrix[corr_matrix < 1]\n",
    "corr_matrix = pd.DataFrame(corr_matrix).reset_index()\n",
    "corr_matrix.columns = ['feature1', 'feature2', 'Correlation']\n",
    "corr_matrix.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a4ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41e4008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 correlated feature groups\n",
      "out of 33 total features.\n"
     ]
    }
   ],
   "source": [
    "# Get groups of features that are correlated amongs themselves\n",
    "grouped_features = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corr_matrix.feature1.unique():\n",
    "    if feature not in grouped_features:\n",
    "        # Find all features correlated to a single feature\n",
    "        correlated_block = corr_matrix[corr_matrix.feature1 == feature]\n",
    "        grouped_features = grouped_features + list(correlated_block.feature2.unique()) + [feature]\n",
    "        \n",
    "        # Append block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('Found {} correlated feature groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features.'.format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cbc5631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          feature1         feature2  Correlation\n",
      "0   perimeter_mean      radius_mean     0.995933\n",
      "5   perimeter_mean        area_mean     0.990699\n",
      "24  perimeter_mean  perimeter_worst     0.923659\n",
      "26  perimeter_mean     radius_worst     0.921552\n",
      "36  perimeter_mean       area_worst     0.889344\n",
      "\n",
      "\n",
      "     feature1      feature2  Correlation\n",
      "12  radius_se  perimeter_se     0.973267\n",
      "14  radius_se       area_se     0.956929\n",
      "\n",
      "\n",
      "          feature1             feature2  Correlation\n",
      "32  concavity_mean  concave points_mean     0.909990\n",
      "47  concavity_mean     compactness_mean     0.836015\n",
      "\n",
      "\n",
      "         feature1      feature2  Correlation\n",
      "38  texture_worst  texture_mean      0.86205\n",
      "\n",
      "\n",
      "             feature1                 feature2  Correlation\n",
      "40  compactness_worst  fractal_dimension_worst     0.847403\n",
      "48  compactness_worst          concavity_worst     0.835064\n",
      "\n",
      "\n",
      "                feature1        feature2  Correlation\n",
      "42  fractal_dimension_se  compactness_se     0.845176\n",
      "\n",
      "\n",
      "                  feature1                 feature2  Correlation\n",
      "44  fractal_dimension_mean  fractal_dimension_worst     0.838737\n",
      "\n",
      "\n",
      "        feature1        feature2  Correlation\n",
      "51  concavity_se  compactness_se     0.813994\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize Correlated Feature Groups\n",
    "for group in correlated_groups:\n",
    "    print(group)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68a65aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"perimeter_mean\",axis=1,inplace=True)\n",
    "df.drop(\"area_mean\",axis=1,inplace=True)\n",
    "df.drop(\"radius_worst\",axis=1,inplace=True)\n",
    "df.drop(\"perimeter_worst\",axis=1,inplace=True)\n",
    "df.drop(\"area_worst\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da630429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"radius_se\",axis=1,inplace=True)\n",
    "df.drop(\"area_se\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "214ef10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"concavity_mean\",axis=1,inplace=True)\n",
    "df.drop(\"texture_worst\",axis=1,inplace=True)\n",
    "df.drop(\"fractal_dimension_worst\",axis=1,inplace=True)\n",
    "df.drop(\"concavity_worst\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c02d280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"compactness_se\",axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f73c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Recurrence</th>\n",
       "      <th>Time</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Lymph node status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119513</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.07055</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.06333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03233</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.01694</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.11950</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8423</td>\n",
       "      <td>N</td>\n",
       "      <td>61</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842517</td>\n",
       "      <td>N</td>\n",
       "      <td>116</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.06010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03300</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>0.03094</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.11880</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.20320</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>843483</td>\n",
       "      <td>N</td>\n",
       "      <td>123</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843584</td>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>942640</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>22.52</td>\n",
       "      <td>21.92</td>\n",
       "      <td>0.07592</td>\n",
       "      <td>0.09162</td>\n",
       "      <td>0.06367</td>\n",
       "      <td>0.1728</td>\n",
       "      <td>0.05262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02433</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>0.02486</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.08191</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.09378</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>943471</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>15.44</td>\n",
       "      <td>31.18</td>\n",
       "      <td>0.09399</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.06500</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.06105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02834</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.02122</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.12860</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>94547</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>17.17</td>\n",
       "      <td>29.19</td>\n",
       "      <td>0.08952</td>\n",
       "      <td>0.06655</td>\n",
       "      <td>0.05068</td>\n",
       "      <td>0.1793</td>\n",
       "      <td>0.05392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03155</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.02734</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.12610</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.09520</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>947204</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>21.42</td>\n",
       "      <td>22.84</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.19390</td>\n",
       "      <td>0.13180</td>\n",
       "      <td>0.1884</td>\n",
       "      <td>0.06472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04948</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.01481</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.14980</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>0.22150</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.211856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>947489</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>16.70</td>\n",
       "      <td>28.13</td>\n",
       "      <td>0.08896</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.04989</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.06035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03957</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.01957</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.13170</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id Recurrence  Time  radius_mean  texture_mean  smoothness_mean  \\\n",
       "0    119513          N    31        18.02         27.60          0.09489   \n",
       "1      8423          N    61        17.99         10.38          0.11840   \n",
       "2    842517          N   116        21.37         17.44          0.08836   \n",
       "3    843483          N   123        11.42         20.38          0.14250   \n",
       "4    843584          R    27        20.29         14.34          0.10030   \n",
       "..      ...        ...   ...          ...           ...              ...   \n",
       "193  942640          N    10        22.52         21.92          0.07592   \n",
       "194  943471          N     8        15.44         31.18          0.09399   \n",
       "195   94547          N    12        17.17         29.19          0.08952   \n",
       "196  947204          R     3        21.42         22.84          0.10700   \n",
       "197  947489          N     6        16.70         28.13          0.08896   \n",
       "\n",
       "     compactness_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.10360              0.07055         0.1865   \n",
       "1             0.27760              0.14710         0.2419   \n",
       "2             0.11890              0.08180         0.2333   \n",
       "3             0.28390              0.10520         0.2597   \n",
       "4             0.13280              0.10430         0.1809   \n",
       "..                ...                  ...            ...   \n",
       "193           0.09162              0.06367         0.1728   \n",
       "194           0.10620              0.06500         0.1735   \n",
       "195           0.06655              0.05068         0.1793   \n",
       "196           0.19390              0.13180         0.1884   \n",
       "197           0.11310              0.04989         0.1890   \n",
       "\n",
       "     fractal_dimension_mean  ...  concavity_se  concave points_se  \\\n",
       "0                   0.06333  ...       0.03233           0.009854   \n",
       "1                   0.07871  ...       0.05373           0.015870   \n",
       "2                   0.06010  ...       0.03300           0.018050   \n",
       "3                   0.09744  ...       0.05661           0.018670   \n",
       "4                   0.05883  ...       0.05688           0.018850   \n",
       "..                      ...  ...           ...                ...   \n",
       "193                 0.05262  ...       0.02433           0.020360   \n",
       "194                 0.06105  ...       0.02834           0.010790   \n",
       "195                 0.05392  ...       0.03155           0.009714   \n",
       "196                 0.06472  ...       0.04948           0.017700   \n",
       "197                 0.06035  ...       0.03957           0.014110   \n",
       "\n",
       "     symmetry_se  fractal_dimension_se  smoothness_worst  compactness_worst  \\\n",
       "0        0.01694              0.003495           0.11950             0.1926   \n",
       "1        0.03003              0.006193           0.16220             0.6656   \n",
       "2        0.03094              0.005039           0.11880             0.3449   \n",
       "3        0.05963              0.009208           0.20980             0.8663   \n",
       "4        0.01756              0.005115           0.13740             0.2050   \n",
       "..           ...                   ...               ...                ...   \n",
       "193      0.02486              0.003922           0.08191             0.1319   \n",
       "194      0.02122              0.003168           0.12720             0.2362   \n",
       "195      0.02734              0.001377           0.12610             0.1572   \n",
       "196      0.01481              0.003979           0.14980             0.4379   \n",
       "197      0.01957              0.003606           0.13300             0.2808   \n",
       "\n",
       "     concave points_worst  symmetry_worst  Tumor Size  Lymph node status  \n",
       "0                 0.11700          0.2677         5.0           5.100000  \n",
       "1                 0.26540          0.4601         3.0           2.000000  \n",
       "2                 0.20320          0.4334         2.5           0.000000  \n",
       "3                 0.25750          0.6638         2.0           0.000000  \n",
       "4                 0.16250          0.2364         3.5           0.000000  \n",
       "..                    ...             ...         ...                ...  \n",
       "193               0.09378          0.2061         6.0           2.000000  \n",
       "194               0.12860          0.2914         1.5           0.000000  \n",
       "195               0.09520          0.3362         3.7           0.000000  \n",
       "196               0.22150          0.2832         3.0           3.211856  \n",
       "197               0.13170          0.3035         3.5           0.000000  \n",
       "\n",
       "[198 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a984b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Recurrence'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df.groupby('Recurrence')\n",
    "   ['id'].nunique()\n",
    "   .plot.bar()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70ea2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tarp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735b06c",
   "metadata": {},
   "source": [
    "## Normalizing skewed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1f0f3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_31148\\3517674506.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.skew(axis = 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                        1.990248\n",
       "Time                      0.514322\n",
       "radius_mean               0.313726\n",
       "texture_mean              0.571373\n",
       "smoothness_mean           0.443359\n",
       "compactness_mean          0.614172\n",
       "concave points_mean       0.697699\n",
       "symmetry_mean             0.775116\n",
       "fractal_dimension_mean    0.999702\n",
       "texture_se                1.309493\n",
       "perimeter_se              1.262808\n",
       "smoothness_se             3.905352\n",
       "concavity_se              1.749850\n",
       "concave points_se         1.280522\n",
       "symmetry_se               2.130190\n",
       "fractal_dimension_se      1.683379\n",
       "smoothness_worst          0.460028\n",
       "compactness_worst         1.165402\n",
       "concave points_worst     -0.147846\n",
       "symmetry_worst            1.120878\n",
       "Tumor Size                1.752621\n",
       "Lymph node status         2.278842\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.skew(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ef69c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smoothness_se']=np.log(df['smoothness_se'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "154941c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_31148\\3038578967.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.skew(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                        1.990248\n",
       "Time                      0.514322\n",
       "radius_mean               0.313726\n",
       "texture_mean              0.571373\n",
       "smoothness_mean           0.443359\n",
       "compactness_mean          0.614172\n",
       "concave points_mean       0.697699\n",
       "symmetry_mean             0.775116\n",
       "fractal_dimension_mean    0.999702\n",
       "texture_se                1.309493\n",
       "perimeter_se              1.262808\n",
       "smoothness_se             0.658615\n",
       "concavity_se              1.749850\n",
       "concave points_se         1.280522\n",
       "symmetry_se               2.130190\n",
       "fractal_dimension_se      1.683379\n",
       "smoothness_worst          0.460028\n",
       "compactness_worst         1.165402\n",
       "concave points_worst     -0.147846\n",
       "symmetry_worst            1.120878\n",
       "Tumor Size                1.752621\n",
       "Lymph node status         2.278842\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.skew(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75e9ebe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>16.11</td>\n",
       "      <td>18.05</td>\n",
       "      <td>105.10</td>\n",
       "      <td>813.0</td>\n",
       "      <td>0.09721</td>\n",
       "      <td>0.11370</td>\n",
       "      <td>0.09447</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.06248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>21.75</td>\n",
       "      <td>20.99</td>\n",
       "      <td>147.30</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>0.09401</td>\n",
       "      <td>0.19610</td>\n",
       "      <td>0.21950</td>\n",
       "      <td>0.10880</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.06194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.34</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.07032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>17.99</td>\n",
       "      <td>20.66</td>\n",
       "      <td>117.80</td>\n",
       "      <td>991.7</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.13040</td>\n",
       "      <td>0.12010</td>\n",
       "      <td>0.08824</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.06069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>16.69</td>\n",
       "      <td>20.20</td>\n",
       "      <td>107.10</td>\n",
       "      <td>857.6</td>\n",
       "      <td>0.07497</td>\n",
       "      <td>0.07112</td>\n",
       "      <td>0.03649</td>\n",
       "      <td>0.02307</td>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.05325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>15.22</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.09429</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.07152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.06777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13.48</td>\n",
       "      <td>20.82</td>\n",
       "      <td>88.40</td>\n",
       "      <td>559.2</td>\n",
       "      <td>0.10160</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.05439</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.06419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17.05</td>\n",
       "      <td>19.08</td>\n",
       "      <td>113.40</td>\n",
       "      <td>895.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.15720</td>\n",
       "      <td>0.19100</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.06325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "65         16.11         18.05          105.10      813.0          0.09721   \n",
       "114        21.75         20.99          147.30     1491.0          0.09401   \n",
       "16         15.34         14.26          102.50      704.4          0.10730   \n",
       "141        17.99         20.66          117.80      991.7          0.10360   \n",
       "156        16.69         20.20          107.10      857.6          0.07497   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "168        15.22         30.62          103.40      716.9          0.10480   \n",
       "38         13.17         18.66           85.98      534.6          0.11580   \n",
       "31         13.48         20.82           88.40      559.2          0.10160   \n",
       "97         17.05         19.08          113.40      895.0          0.11410   \n",
       "172        16.60         28.08          108.30      858.1          0.08455   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "65            0.11370         0.09447              0.05943         0.1861   \n",
       "114           0.19610         0.21950              0.10880         0.1721   \n",
       "16            0.21350         0.20770              0.09756         0.2521   \n",
       "141           0.13040         0.12010              0.08824         0.1992   \n",
       "156           0.07112         0.03649              0.02307         0.1846   \n",
       "..                ...             ...                  ...            ...   \n",
       "168           0.20870         0.25500              0.09429         0.2128   \n",
       "38            0.12310         0.12260              0.07340         0.2128   \n",
       "31            0.12550         0.10630              0.05439         0.1720   \n",
       "97            0.15720         0.19100              0.10900         0.2131   \n",
       "172           0.10230         0.09251              0.05302         0.1590   \n",
       "\n",
       "     fractal_dimension_mean  \n",
       "65                  0.06248  \n",
       "114                 0.06194  \n",
       "16                  0.07032  \n",
       "141                 0.06069  \n",
       "156                 0.05325  \n",
       "..                      ...  \n",
       "168                 0.07152  \n",
       "38                  0.06777  \n",
       "31                  0.06419  \n",
       "97                  0.06325  \n",
       "172                 0.05648  \n",
       "\n",
       "[66 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[:,1:11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4db5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "206646cb",
   "metadata": {},
   "source": [
    "## Applying ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd846221",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,2:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d08ed273",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Recurrence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84527106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebe89e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.3030303030303"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logModel=LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "logModel.fit(X_train, y_train)\n",
    "predictions = logModel.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15a75d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6785714285714286, 0.6451378809869376, 0.6577582768248904, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support#Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision_recall_fscore_support(y_test, predictions, average='macro')#Recall = TruePositives / (TruePositives + FalseNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f7f55c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model accuracy score: 87.8788\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d0f9cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8181818181818181, 0.7793904208998549, 0.7962962962962963, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "721100a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9444e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25d1c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                         8910988\n",
      "Recurrence                       R\n",
      "Time                             5\n",
      "radius_mean                  21.75\n",
      "texture_mean                 20.99\n",
      "smoothness_mean            0.09401\n",
      "compactness_mean            0.1961\n",
      "concave points_mean         0.1088\n",
      "symmetry_mean               0.1721\n",
      "fractal_dimension_mean     0.06194\n",
      "texture_se                   1.352\n",
      "perimeter_se                 8.867\n",
      "smoothness_se            -5.169572\n",
      "concavity_se               0.06329\n",
      "concave points_se          0.01561\n",
      "symmetry_se                0.01924\n",
      "fractal_dimension_se      0.004614\n",
      "smoothness_worst            0.1272\n",
      "compactness_worst           0.4725\n",
      "concave points_worst        0.1841\n",
      "symmetry_worst              0.2833\n",
      "Tumor Size                     2.5\n",
      "Lymph node status             11.0\n",
      "Name: 114, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1c41e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94d123b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 100) \n",
    " \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred8 = clf.predict(X_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6390e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "84.84848484848484\n"
     ]
    }
   ],
   "source": [
    "# metrics are used to find accuracy or error\n",
    "from sklearn import metrics \n",
    "print()\n",
    " \n",
    "# using metrics module for accuracy calculation\n",
    "print( metrics.accuracy_score(y_test, y_pred8)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2293451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8262295081967213, 0.6444121915820029, 0.6783625730994152, None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred8, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d773dcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.81818181818183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100,max_depth=6,min_samples_split=2,min_weight_fraction_leaf =0.0,n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test)*100)\n",
    "y_pred9 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db0ce184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.746031746031746, 0.567489114658926, 0.5732758620689655, None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred9, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de37360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5f0e6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.75757575757575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    " \n",
    "knn.fit(X_train, y_train)\n",
    " \n",
    "# Predict on dataset which model has not seen before\n",
    "print(knn.score(X_test, y_test)*100)\n",
    "y_pred10 = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebd2ad7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.549636803874092, 0.5297532656023223, 0.5285714285714286, None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred10, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1eb8ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.78787878787878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = SVC(kernel='linear') \n",
    "  \n",
    "#fitting x samples and y classes \n",
    "clf.fit(X_train, y_train) \n",
    "y_pred2=clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6437c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6295399515738499, 0.5776487663280117, 0.5875, None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred2, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d2eb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "  \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "y= label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ff0871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6a7a98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = XGBClassifier(eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred1 = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95c68849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7435344827586207, 0.6640058055152395, 0.6885456885456885, None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred1, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4b5944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59648134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential #Helps to create Forward and backward propogation\n",
    "from tensorflow.keras.layers import Dense #Helps to create neurons in ANN\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU #activation functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ed198de",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6e36c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=11,activation='relu')) #The no. of units can vary roughly between 1 and the total no. of inputs . The change in the no. of units will change in the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4297435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=7,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9be65f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classifier.add(Dense(units=6,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "869ce5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Adding the output layer\n",
    "classifier.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d7a52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "#classifier.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33485b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "#opt=tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "582caec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Early stopping Keras\n",
    "import tensorflow as tf\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f09f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#baseline: Baseline value for the monitored quantity. Training will stop if the model doesn't show improvement over the baseline.\n",
    "#mode: One of {\"auto\", \"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing; in \"max\" mode it will stop when the quantity monitored has stopped increasing\n",
    "#; in \"auto\" mode, the direction is automatically inferred from the name of the monitored quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "366bd1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 132 entries, 41 to 102\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Time                    132 non-null    int64  \n",
      " 1   radius_mean             132 non-null    float64\n",
      " 2   texture_mean            132 non-null    float64\n",
      " 3   smoothness_mean         132 non-null    float64\n",
      " 4   compactness_mean        132 non-null    float64\n",
      " 5   concave points_mean     132 non-null    float64\n",
      " 6   symmetry_mean           132 non-null    float64\n",
      " 7   fractal_dimension_mean  132 non-null    float64\n",
      " 8   texture_se              132 non-null    float64\n",
      " 9   perimeter_se            132 non-null    float64\n",
      " 10  smoothness_se           132 non-null    float64\n",
      " 11  concavity_se            132 non-null    float64\n",
      " 12  concave points_se       132 non-null    float64\n",
      " 13  symmetry_se             132 non-null    float64\n",
      " 14  fractal_dimension_se    132 non-null    float64\n",
      " 15  smoothness_worst        132 non-null    float64\n",
      " 16  compactness_worst       132 non-null    float64\n",
      " 17  concave points_worst    132 non-null    float64\n",
      " 18  symmetry_worst          132 non-null    float64\n",
      " 19  Tumor Size              132 non-null    float64\n",
      " 20  Lymph node status       132 non-null    float64\n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 22.7 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39f7ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 2s 52ms/step - loss: 1.6570 - accuracy: 0.3636 - val_loss: 1.3217 - val_accuracy: 0.2500\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.2939 - accuracy: 0.3977 - val_loss: 1.0297 - val_accuracy: 0.4091\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0035 - accuracy: 0.4659 - val_loss: 0.7072 - val_accuracy: 0.6818\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7083 - accuracy: 0.6364 - val_loss: 0.5232 - val_accuracy: 0.7727\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5715 - accuracy: 0.7386 - val_loss: 0.4952 - val_accuracy: 0.7955\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5553 - accuracy: 0.7500 - val_loss: 0.4905 - val_accuracy: 0.7955\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5517 - accuracy: 0.7386 - val_loss: 0.4944 - val_accuracy: 0.7273\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5471 - accuracy: 0.7273 - val_loss: 0.4974 - val_accuracy: 0.7045\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5455 - accuracy: 0.7273 - val_loss: 0.5000 - val_accuracy: 0.7045\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5417 - accuracy: 0.7273 - val_loss: 0.4913 - val_accuracy: 0.7273\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5374 - accuracy: 0.7614 - val_loss: 0.4852 - val_accuracy: 0.7273\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5338 - accuracy: 0.7500 - val_loss: 0.4824 - val_accuracy: 0.7500\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5318 - accuracy: 0.7500 - val_loss: 0.4850 - val_accuracy: 0.7273\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5287 - accuracy: 0.7500 - val_loss: 0.4885 - val_accuracy: 0.7273\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5270 - accuracy: 0.7500 - val_loss: 0.4833 - val_accuracy: 0.7273\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5241 - accuracy: 0.7500 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5218 - accuracy: 0.7500 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.4917 - val_accuracy: 0.7045\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5179 - accuracy: 0.7500 - val_loss: 0.4870 - val_accuracy: 0.7273\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5161 - accuracy: 0.7500 - val_loss: 0.4848 - val_accuracy: 0.7273\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5163 - accuracy: 0.7500 - val_loss: 0.4926 - val_accuracy: 0.7273\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5133 - accuracy: 0.7500 - val_loss: 0.4877 - val_accuracy: 0.7500\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5091 - accuracy: 0.7500 - val_loss: 0.4891 - val_accuracy: 0.7273\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5091 - accuracy: 0.7614 - val_loss: 0.4957 - val_accuracy: 0.7273\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5062 - accuracy: 0.7614 - val_loss: 0.4900 - val_accuracy: 0.7273\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5050 - accuracy: 0.7386 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.4939 - val_accuracy: 0.7273\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5013 - accuracy: 0.7727 - val_loss: 0.4911 - val_accuracy: 0.7273\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5014 - accuracy: 0.7727 - val_loss: 0.4940 - val_accuracy: 0.7273\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4994 - accuracy: 0.7614 - val_loss: 0.4855 - val_accuracy: 0.7273\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4963 - accuracy: 0.7386 - val_loss: 0.4848 - val_accuracy: 0.7500\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4966 - accuracy: 0.7614 - val_loss: 0.4920 - val_accuracy: 0.7273\n",
      "Epoch 32: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_history=classifier.fit(X_train,y_train,validation_split=0.33,batch_size=10,epochs=1000,callbacks=early_stopping)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a2a8a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79c82407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "719fe884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803030303030303"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e08561a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6612903225806452, 0.558055152394775, 0.5611253196930946, None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support #Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "precision_recall_fscore_support(y_test, y_pred, average='macro')#Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "#F score = (2 * Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "469c90d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  2],\n",
       "       [11,  2]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b795869",
   "metadata": {},
   "source": [
    "## Balanced Class Weight Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dbe6d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 200,class_weight='balanced') \n",
    " \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred8 = clf.predict(X_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f65a76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "84.84848484848484\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print()\n",
    " \n",
    "# using metrics module for accuracy calculation\n",
    "print( metrics.accuracy_score(y_test, y_pred8)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb2b14e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8262295081967213, 0.6444121915820029, 0.6783625730994152, None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balanced Random Forest\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred8 ,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1930a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.72727272727273"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balanced\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logModel=LogisticRegression(solver='lbfgs', max_iter=1000000,class_weight='balanced')\n",
    "logModel.fit(X_train, y_train,)\n",
    "predictions = logModel.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0556a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6634146341463415, 0.7431059506531205, 0.6674132138857782, None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balanced logistic Regresssion\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5a9503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.81818181818183\n"
     ]
    }
   ],
   "source": [
    "#balanced\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100,max_depth=6,min_samples_split=2,min_weight_fraction_leaf =0.0,n_jobs=-1,class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test)*100)\n",
    "y_pred9 = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "84f32669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86fd4d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7176470588235294, 0.7416545718432511, 0.7280219780219781, None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balanced Extratree classifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred9, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd12e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.15151515151516\n"
     ]
    }
   ],
   "source": [
    "#balanced\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = SVC(kernel='linear',class_weight='balanced') \n",
    "  \n",
    "#fitting x samples and y classes \n",
    "clf.fit(X_train, y_train) \n",
    "y_pred2=clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6493ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6080827067669173, 0.6669085631349783, 0.5931385687483248, None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balanced svm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred2, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa70f1",
   "metadata": {},
   "source": [
    "## Reducing no. of Columns PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8362e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_n=PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2618bc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_n.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bdab14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_n=pca_n.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2caebde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.99982181480833"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca_n.explained_variance_ratio_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c96fd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([94.93410889, 97.31637047, 98.69228049, 99.55235438, 99.77357819,\n",
       "       99.97462217, 99.99078529, 99.99719936, 99.99957426, 99.99982181])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca_n.explained_variance_ratio_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1784ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explained variance')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca_n.explained_variance_ratio_*100))\n",
    "plt.xlabel('No. of components')\n",
    "plt.ylabel('Explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81dbfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_98=PCA(n_components=0.99,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1cc5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_98.fit(X)\n",
    "X_pca_98=pca_98.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ec4b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=pd.DataFrame(X_pca_98,columns=['PC1','PC2','PC3','PC4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a7605066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3c58b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba4b2671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model accuracy score: 83.3333\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a30ae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7375, 0.6930333817126271, 0.710410849621061, None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "577d70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.81818181818183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100,max_depth=6,min_samples_split=2,min_weight_fraction_leaf =0.0,n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test)*100)\n",
    "y_pred1=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e69d3e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7094430992736077, 0.625544267053701, 0.6464285714285714, None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred1, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68899c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 200) \n",
    " \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred8 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3bdc80d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "81.81818181818183\n"
     ]
    }
   ],
   "source": [
    "# metrics are used to find accuracy or error\n",
    "from sklearn import metrics \n",
    "print()\n",
    " \n",
    "# using metrics module for accuracy calculation\n",
    "print( metrics.accuracy_score(y_test, y_pred8)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc7130db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.709090909090909, 0.683599419448476, 0.6944444444444444, None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred8, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1d94a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    " \n",
    "knn.fit(X_train, y_train)\n",
    " \n",
    "# Predict on dataset which model has not seen before\n",
    "print(knn.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e56e9993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred7 = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc769e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7583333333333333, 0.634978229317852, 0.6618537494177923, None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred7, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef15cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.3030303030303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "clf = SVC(kernel='linear') \n",
    "  \n",
    "#fitting x samples and y classes \n",
    "clf.fit(X_train, y_train) \n",
    "y_pred2=clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "174c97fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65625, 0.5290275761973875, 0.5111111111111111, None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred2, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c3a8fb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.84848484848484"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logModel=LogisticRegression(solver='lbfgs', max_iter=100,dual=False)\n",
    "logModel.fit(X_train, y_train,)\n",
    "predictions = logModel.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef5bab54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7893462469733656, 0.6734397677793904, 0.7053571428571428, None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "69778245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = XGBClassifier(eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred1 = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1bf24a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7376373626373627, 0.7510885341074021, 0.743915343915344, None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred1, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fbc1e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "700280cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1.add(Dense(units=3,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3b00caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1.add(Dense(units=2,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "34d325d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier1.add(Dense(units=2,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "02518c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding the output layer\n",
    "classifier1.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6f911e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier1.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "#classifier.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "759140aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 2s 37ms/step - loss: 0.6899 - accuracy: 0.5455 - val_loss: 0.6786 - val_accuracy: 0.7045\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6814 - accuracy: 0.6477 - val_loss: 0.6696 - val_accuracy: 0.7500\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6788 - accuracy: 0.6818 - val_loss: 0.6631 - val_accuracy: 0.7727\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6751 - accuracy: 0.6932 - val_loss: 0.6589 - val_accuracy: 0.7727\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.7159 - val_loss: 0.6547 - val_accuracy: 0.7727\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6709 - accuracy: 0.7045 - val_loss: 0.6496 - val_accuracy: 0.7727\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6683 - accuracy: 0.7159 - val_loss: 0.6451 - val_accuracy: 0.7500\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6660 - accuracy: 0.6932 - val_loss: 0.6404 - val_accuracy: 0.7955\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6636 - accuracy: 0.7159 - val_loss: 0.6356 - val_accuracy: 0.7727\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6614 - accuracy: 0.7045 - val_loss: 0.6307 - val_accuracy: 0.7727\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6593 - accuracy: 0.7045 - val_loss: 0.6258 - val_accuracy: 0.7727\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6569 - accuracy: 0.7045 - val_loss: 0.6215 - val_accuracy: 0.7955\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6545 - accuracy: 0.7159 - val_loss: 0.6179 - val_accuracy: 0.7955\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6524 - accuracy: 0.7273 - val_loss: 0.6135 - val_accuracy: 0.8182\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6506 - accuracy: 0.7386 - val_loss: 0.6080 - val_accuracy: 0.8182\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6477 - accuracy: 0.7273 - val_loss: 0.6040 - val_accuracy: 0.8182\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.7273 - val_loss: 0.5989 - val_accuracy: 0.8409\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6428 - accuracy: 0.7273 - val_loss: 0.5938 - val_accuracy: 0.8409\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6401 - accuracy: 0.7273 - val_loss: 0.5886 - val_accuracy: 0.8409\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6372 - accuracy: 0.7159 - val_loss: 0.5839 - val_accuracy: 0.8409\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6345 - accuracy: 0.7159 - val_loss: 0.5795 - val_accuracy: 0.8409\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6324 - accuracy: 0.7159 - val_loss: 0.5751 - val_accuracy: 0.8409\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6297 - accuracy: 0.7159 - val_loss: 0.5718 - val_accuracy: 0.8409\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6274 - accuracy: 0.7159 - val_loss: 0.5679 - val_accuracy: 0.8409\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6250 - accuracy: 0.7159 - val_loss: 0.5639 - val_accuracy: 0.8409\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6229 - accuracy: 0.7159 - val_loss: 0.5593 - val_accuracy: 0.8409\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6206 - accuracy: 0.7159 - val_loss: 0.5548 - val_accuracy: 0.8409\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6178 - accuracy: 0.7159 - val_loss: 0.5517 - val_accuracy: 0.8409\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6162 - accuracy: 0.7159 - val_loss: 0.5470 - val_accuracy: 0.8409\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6134 - accuracy: 0.7159 - val_loss: 0.5433 - val_accuracy: 0.8409\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.7159 - val_loss: 0.5392 - val_accuracy: 0.8409\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6087 - accuracy: 0.7159 - val_loss: 0.5361 - val_accuracy: 0.8409\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6063 - accuracy: 0.7273 - val_loss: 0.5327 - val_accuracy: 0.8409\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6039 - accuracy: 0.7273 - val_loss: 0.5284 - val_accuracy: 0.8409\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6012 - accuracy: 0.7273 - val_loss: 0.5241 - val_accuracy: 0.8409\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.7273 - val_loss: 0.5203 - val_accuracy: 0.8409\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5964 - accuracy: 0.7273 - val_loss: 0.5169 - val_accuracy: 0.8409\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5939 - accuracy: 0.7273 - val_loss: 0.5133 - val_accuracy: 0.8409\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5919 - accuracy: 0.7273 - val_loss: 0.5099 - val_accuracy: 0.8409\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5896 - accuracy: 0.7273 - val_loss: 0.5063 - val_accuracy: 0.8409\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5874 - accuracy: 0.7273 - val_loss: 0.5034 - val_accuracy: 0.8409\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5854 - accuracy: 0.7386 - val_loss: 0.5009 - val_accuracy: 0.8409\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5840 - accuracy: 0.7386 - val_loss: 0.4972 - val_accuracy: 0.8182\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5820 - accuracy: 0.7273 - val_loss: 0.4953 - val_accuracy: 0.8182\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5798 - accuracy: 0.7273 - val_loss: 0.4927 - val_accuracy: 0.8182\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5783 - accuracy: 0.7273 - val_loss: 0.4898 - val_accuracy: 0.8182\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5764 - accuracy: 0.7273 - val_loss: 0.4872 - val_accuracy: 0.8182\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5746 - accuracy: 0.7386 - val_loss: 0.4856 - val_accuracy: 0.8182\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5731 - accuracy: 0.7500 - val_loss: 0.4829 - val_accuracy: 0.8182\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5715 - accuracy: 0.7500 - val_loss: 0.4813 - val_accuracy: 0.8182\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5698 - accuracy: 0.7500 - val_loss: 0.4805 - val_accuracy: 0.8182\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5686 - accuracy: 0.7500 - val_loss: 0.4782 - val_accuracy: 0.8182\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.4762 - val_accuracy: 0.8182\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.4752 - val_accuracy: 0.8182\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.4733 - val_accuracy: 0.8182\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.4719 - val_accuracy: 0.8182\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5616 - accuracy: 0.7500 - val_loss: 0.4720 - val_accuracy: 0.8182\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5603 - accuracy: 0.7500 - val_loss: 0.4695 - val_accuracy: 0.8182\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5589 - accuracy: 0.7500 - val_loss: 0.4690 - val_accuracy: 0.8182\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5576 - accuracy: 0.7500 - val_loss: 0.4677 - val_accuracy: 0.8182\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5562 - accuracy: 0.7500 - val_loss: 0.4662 - val_accuracy: 0.8182\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5551 - accuracy: 0.7500 - val_loss: 0.4652 - val_accuracy: 0.8182\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5538 - accuracy: 0.7500 - val_loss: 0.4646 - val_accuracy: 0.8182\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5526 - accuracy: 0.7500 - val_loss: 0.4635 - val_accuracy: 0.8182\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5516 - accuracy: 0.7500 - val_loss: 0.4646 - val_accuracy: 0.8409\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5507 - accuracy: 0.7500 - val_loss: 0.4630 - val_accuracy: 0.8409\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5491 - accuracy: 0.7500 - val_loss: 0.4631 - val_accuracy: 0.8409\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5484 - accuracy: 0.7500 - val_loss: 0.4640 - val_accuracy: 0.8636\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5471 - accuracy: 0.7500 - val_loss: 0.4637 - val_accuracy: 0.8636\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5460 - accuracy: 0.7500 - val_loss: 0.4634 - val_accuracy: 0.8636\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5452 - accuracy: 0.7500 - val_loss: 0.4633 - val_accuracy: 0.8636\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5440 - accuracy: 0.7500 - val_loss: 0.4621 - val_accuracy: 0.8636\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5431 - accuracy: 0.7500 - val_loss: 0.4622 - val_accuracy: 0.8636\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5418 - accuracy: 0.7500 - val_loss: 0.4618 - val_accuracy: 0.8636\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5406 - accuracy: 0.7500 - val_loss: 0.4625 - val_accuracy: 0.8409\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5383 - accuracy: 0.7500 - val_loss: 0.4611 - val_accuracy: 0.8636\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5366 - accuracy: 0.7500 - val_loss: 0.4607 - val_accuracy: 0.8636\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5352 - accuracy: 0.7500 - val_loss: 0.4614 - val_accuracy: 0.8636\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5334 - accuracy: 0.7614 - val_loss: 0.4620 - val_accuracy: 0.8636\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5324 - accuracy: 0.7614 - val_loss: 0.4628 - val_accuracy: 0.8636\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5310 - accuracy: 0.7614 - val_loss: 0.4617 - val_accuracy: 0.8636\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5299 - accuracy: 0.7614 - val_loss: 0.4615 - val_accuracy: 0.8636\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.7614 - val_loss: 0.4609 - val_accuracy: 0.8636\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5283 - accuracy: 0.7614 - val_loss: 0.4601 - val_accuracy: 0.8636\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5272 - accuracy: 0.7614 - val_loss: 0.4585 - val_accuracy: 0.8409\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5265 - accuracy: 0.7614 - val_loss: 0.4582 - val_accuracy: 0.8636\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5257 - accuracy: 0.7614 - val_loss: 0.4578 - val_accuracy: 0.8636\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5248 - accuracy: 0.7614 - val_loss: 0.4575 - val_accuracy: 0.8636\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5244 - accuracy: 0.7614 - val_loss: 0.4599 - val_accuracy: 0.8636\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5222 - accuracy: 0.7614 - val_loss: 0.4596 - val_accuracy: 0.8636\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5213 - accuracy: 0.7614 - val_loss: 0.4594 - val_accuracy: 0.8636\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5212 - accuracy: 0.7614 - val_loss: 0.4619 - val_accuracy: 0.8636\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5190 - accuracy: 0.7614 - val_loss: 0.4594 - val_accuracy: 0.8636\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5180 - accuracy: 0.7614 - val_loss: 0.4586 - val_accuracy: 0.8636\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5173 - accuracy: 0.7614 - val_loss: 0.4582 - val_accuracy: 0.8409\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5162 - accuracy: 0.7614 - val_loss: 0.4565 - val_accuracy: 0.8409\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5161 - accuracy: 0.7614 - val_loss: 0.4580 - val_accuracy: 0.8409\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5145 - accuracy: 0.7614 - val_loss: 0.4563 - val_accuracy: 0.8409\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5137 - accuracy: 0.7614 - val_loss: 0.4563 - val_accuracy: 0.8409\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5132 - accuracy: 0.7614 - val_loss: 0.4560 - val_accuracy: 0.8409\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5122 - accuracy: 0.7614 - val_loss: 0.4548 - val_accuracy: 0.8409\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5116 - accuracy: 0.7614 - val_loss: 0.4543 - val_accuracy: 0.8409\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5112 - accuracy: 0.7614 - val_loss: 0.4548 - val_accuracy: 0.8409\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5104 - accuracy: 0.7614 - val_loss: 0.4539 - val_accuracy: 0.8409\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5096 - accuracy: 0.7614 - val_loss: 0.4530 - val_accuracy: 0.8409\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5089 - accuracy: 0.7500 - val_loss: 0.4537 - val_accuracy: 0.8409\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5084 - accuracy: 0.7500 - val_loss: 0.4526 - val_accuracy: 0.8409\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5076 - accuracy: 0.7500 - val_loss: 0.4516 - val_accuracy: 0.8409\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5084 - accuracy: 0.7500 - val_loss: 0.4546 - val_accuracy: 0.8409\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5067 - accuracy: 0.7500 - val_loss: 0.4507 - val_accuracy: 0.8409\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.4514 - val_accuracy: 0.8409\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5051 - accuracy: 0.7500 - val_loss: 0.4504 - val_accuracy: 0.8409\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5046 - accuracy: 0.7500 - val_loss: 0.4512 - val_accuracy: 0.8409\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5041 - accuracy: 0.7500 - val_loss: 0.4509 - val_accuracy: 0.8409\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5035 - accuracy: 0.7500 - val_loss: 0.4518 - val_accuracy: 0.8409\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.7500 - val_loss: 0.4505 - val_accuracy: 0.8409\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5023 - accuracy: 0.7500 - val_loss: 0.4499 - val_accuracy: 0.8409\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5022 - accuracy: 0.7500 - val_loss: 0.4476 - val_accuracy: 0.8409\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5020 - accuracy: 0.7500 - val_loss: 0.4475 - val_accuracy: 0.8409\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5009 - accuracy: 0.7500 - val_loss: 0.4492 - val_accuracy: 0.8409\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5001 - accuracy: 0.7500 - val_loss: 0.4490 - val_accuracy: 0.8409\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4994 - accuracy: 0.7500 - val_loss: 0.4509 - val_accuracy: 0.8409\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4986 - accuracy: 0.7500 - val_loss: 0.4502 - val_accuracy: 0.8409\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4976 - accuracy: 0.7500 - val_loss: 0.4500 - val_accuracy: 0.8409\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4972 - accuracy: 0.7500 - val_loss: 0.4521 - val_accuracy: 0.8409\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4957 - accuracy: 0.7500 - val_loss: 0.4505 - val_accuracy: 0.8409\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4951 - accuracy: 0.7500 - val_loss: 0.4500 - val_accuracy: 0.8636\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4948 - accuracy: 0.7500 - val_loss: 0.4523 - val_accuracy: 0.8636\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4933 - accuracy: 0.7500 - val_loss: 0.4525 - val_accuracy: 0.8636\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4927 - accuracy: 0.7500 - val_loss: 0.4529 - val_accuracy: 0.8636\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4919 - accuracy: 0.7500 - val_loss: 0.4518 - val_accuracy: 0.8409\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4913 - accuracy: 0.7500 - val_loss: 0.4538 - val_accuracy: 0.8409\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4907 - accuracy: 0.7500 - val_loss: 0.4544 - val_accuracy: 0.8409\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4901 - accuracy: 0.7500 - val_loss: 0.4528 - val_accuracy: 0.8409\n",
      "Epoch 135/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4896 - accuracy: 0.7500 - val_loss: 0.4554 - val_accuracy: 0.8182\n",
      "Epoch 136/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4885 - accuracy: 0.7500 - val_loss: 0.4545 - val_accuracy: 0.8409\n",
      "Epoch 137/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4881 - accuracy: 0.7500 - val_loss: 0.4539 - val_accuracy: 0.8409\n",
      "Epoch 138/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4876 - accuracy: 0.7614 - val_loss: 0.4575 - val_accuracy: 0.8182\n",
      "Epoch 139/1000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4870 - accuracy: 0.7614 - val_loss: 0.4570 - val_accuracy: 0.8182\n",
      "Epoch 139: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier1.fit(X_train,y_train,validation_split=0.33,batch_size=10,epochs=1000,callbacks=early_stopping)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3f869d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier1.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3559da6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd81b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dead48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef799ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415bc089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
